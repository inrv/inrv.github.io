<!DOCTYPE html>
<html>

<head>

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords"
    content="implicit neural representation, neural fields, INR, deep learning, computer vision, university of maryland, machine learning">

  <!--  <link rel="shortcut icon" href="visualgenome_logo.png">-->

  <title>Implicit Neural Representation for Vision</title>
  <meta name="description" content="Implicit Neural Representation for Vision">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="Implicit Neural Representation for Vision" />
  <meta property="og:url" content="https://inrv.github.io" />
  <meta property="og:description" content="Exploring implicit neural representation in computer vision ---" />
  <meta property="og:site_name" content="Implicit Neural Representation for Vision" />

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css">

  <!-- Style -->
  <link rel="stylesheet" type="text/css" href="style.css" media="screen,projection">
</head>

<body>

  <!-- <div class="top-strip"></div> -->
  <div class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <a class="navbar-brand" href="https://inrv.github.io">Implicit Neural Representation for Vision</a>
        <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <div class="navbar-collapse collapse" id="navbar-main">
        <ul class="nav navbar-nav">
          <li>
            <!--  TODO: change logo  -->
          </li>
        </ul>
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a href="#overview">Overview</a>
          </li>
          <li>
            <a href="#papers">Call for Papers</a>
          </li>
          <li>
            <a href="#schedule">Schedule</a>
          </li>
          <li>
            <a href="#speakers">Keynote Speakers</a>
          </li>
          <li>
            <a href="#organizers">Organizers</a>
          </li>
          <!--        <li>-->
          <!--          <a href="#accepted">Accepted papers</a>-->
          <!--        </li>-->
        </ul>
      </div>
    </div>
  </div>


  <div class="container">
    <div class="page-content">

      <div class="row">
        <div class="col-xs-12">
          <h1><b>Implicit Neural Representation for Vision</b></h1>
          <h3>June 17th or 18th (TBD soon), held in conjunction with <a href="http://cvpr2024.thecvf.com" target="_blank">CVPR 2024</a></h3>
          <!--          <h3>Location: Room 318 B-C in at the COEX Convention Center</h3>-->
          <!--          <br />-->
          <!--          <img src='images/ezgif.com-video-to-gif.gif' />-->
          <!--  TODO: construct a teaser figure        -->
          <!--          <br />-->
        </div>
      </div>

      <hr />

      <!-- Overview -->
      <p><a class="anchor" id="overview"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Overview</h2>
          <p>An emerging area within deep learning, implicit neural representation (INR), also known as neural fields,
            offers a powerful new mechanism and paradigm for processing and representing visual data.In contrast with
            the dominant big data setting, INR focuses on neural networks which parameterize a field, often in a
            coordinate-based manner. The most well-known of this class of models is NeRF, which has been wildly
            successful for 3D modeling, especially for novel view synthesis. INR for 2D images and videos have many
            compelling properties as well, particularly for visual data compression. By treating the weights of the
            networks as the data itself and leveraging their implicit reconstruction ability, several multimodal
            compression techniques have been developed. </p>

          <p>This is a relatively new area in vision, with many opportunities to propose new algorithms, extend existing
            applications, and innovate entirely new systems. Since working with INRs often requires less resources than
            many areas, this sort of research is especially accessible in the academic setting. Additionally, while
            there are many workshops for NeRF, there are often none for the incredibly broad spectrum of other INR work.
            Therefore, we propose this workshop as an avenue to build up the fledgling INR community, and help
            disseminate knowledge in the field about this exciting area. We thus invite researchers to the Workshop for
            Implicit Neural Representation for Vision (INRV) where we investigate multiple directions, challenges, and
            opportunities related to implicit neural representation. </p>

          <p>The simple design and flexibility offered by INRs, and recent work that leverages these models for
            generative tasks and proposes hypernetworks to circumvent expensive per-model training, points to the
            potential of INR a unified architecture that can efficiently represent audio, images, video and 3D data. The
            following are some of the key directions and challenges in INR. </p>

          <p>Compression is learning: An efficient data compressor is also an efficient learner. A good compressor is a
            step towards learning a good data representation for downstream tasks. </p>
          <p>Generalizing INRs: INRs leverage neural networks to compress individual data points. However, a more
            efficient approach would be to devise methods that can identify patterns within a dataset and generalize to
            unseen data points. Currently, the prolonged training time is a significant drawback of INRs due to the
            overfitting of each data point. Several meta-learning methods have been introduced to address this, reducing
            the training time from hours to just seconds. </p>
          <p>Unified architecture: The advantage of having a network with implicit inputs is that it can, at least in
            theory, be used to represent all kinds of data - images, video, audio and 3D using the same network
            architecture - a holy grail for the field. </p>
        </div>
      </div>

      <hr />

      <!-- Call for Papers -->
      <p><a class="anchor" id="papers"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Call for Papers</h2>
          INRV will have an 8-page CVPR proceedings track. Note that 8 pages is a maximum; shorter submissions, given they are original and of good quality, are also permissible.
          All submissions must follow the CVPR 2024 style guide, since if accepted they will be published in the conference proceedings.
          <ul>
            <li>
              <b>Submission Deadline:</b> March 21st, 11:59 PM Pacific Time
            </li>
            <li>
              <b>Acceptance Notification:</b> April 24th, 11:59 PM Pacific Time
            </li>
            <li>
              <b>Camera Ready:</b> May 3rd, 11:59 PM Pacific Time
            </li>
            <li>
              <b>Submission Website:</b> CMT (Coming Soon!)
            </li>
          </ul>
          <p>Papers ought to describe original research that leverages implicit neural representation to solve some computer vision problem. Topics of interest are those
            which lie at the intersection of computer vision and implicit neural representation, including but not limited to:
          </p>
          <ul>
            <li>
              Compression: Image, Video, Scene
            </li>
            <li>
              Restoration: Denoising, Inpainting
            </li>
            <li>
              Enhancement: Interpolation, Superresolution
            </li>
            <li>
              Hypernetworks
            </li>
            <li>
              Optimization: Reducing model size and training time
            </li>
            <li>
              Generation: Generating videos, scenes, images
            </li>
            <li>
              Recognition: Classification, detection, segmentation
            </li>
          </ul>
        </div>
      </div>

      <!-- Participation -->
      <p><a class="anchor" id="participation"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Participation</h2>
          <p> Each workshop paper must be registered under a full, in-person registration type ("AUTHOR / FULL PASSPORT").</p>
          <a href="https://cvpr.thecvf.com/Conferences/2024/Pricing2">Register here</a>
        </div>
      </div>

      <!-- Submission -->
      <p><a class="anchor" id="cmt"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Submission</h2>
          <p class="important">Submit in this CMT portal (coming soon!): <a
              href="TBD">TBD</a></p>
        </div>
      </div>
      
      <hr />

      <!-- Schedule -->
      <p><a class="anchor" id="schedule"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Program Schedule</h2>
        </div>
      </div>

      <div class="row slot-dark">
        <div class="col-xs-12 col-sm-2">
          Time (Pacific Time, UTC-7)
        </div>
        <div class="col-xs-12 col-sm-2">
          Event
        </div>
        <div class="col-xs-12 col-sm-6">
          Title/Presenter
        </div>
      </div>

      <div class="row slot">

        <div class="col-xs-12 col-sm-2">
          TBD
        </div>
        <div class="col-xs-12 col-sm-2">
          TBD
        </div>
        <div class="col-xs-12 col-sm-6">
          <a href='TBD' target="_blank"><strong>TBD</strong></a>,
          <span style='color:#999999;'>TBD</span>
        </div>
      </div>



      <!--

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          08:45 - 10:15
        </div>
        <div class="col-xs-12 col-sm-2">
          Keynote talk
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Composition in Concept, Space and Time</strong><br />
          <a href='https://www.cs.cmu.edu/~abhinavg/' target="_blank"><strong>Abhinav Gupta</strong></a>,
          <span style='color:#999999;'>Carnegie Mellon University</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Meta-Learning Symmetries and Distributions</strong><br />
          <a href='https://ai.stanford.edu/~cbfinn/' target="_blank"><strong>Chelsea Finn</strong></a>,
          <span style='color:#999999;'>Stanford University</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          10:15 - 11:00
        </div>
        <div class="col-xs-12 col-sm-2">
          Keynote talk
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>A Roadmap for Activity and Event Recognition Models</strong><br />
          <a href='http://olivalab.mit.edu/audeoliva.html' target="_blank"><strong>Aude Oliva</strong></a>,
          <span style='color:#999999;'>Massachusetts Institute of Technology</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          11:00 - 11:45
        </div>
        <div class="col-xs-12 col-sm-2">
          Keynote talk
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>What next in Computer Vision</strong><br />
          <a href='https://people.eecs.berkeley.edu/~malik/' target="_blank"><strong>Jitendra Malik</strong></a>,
          <span style='color:#999999;'>University of California, Berkeley</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          11:45 - 12:30
        </div>
        <div class="col-xs-12 col-sm-2">
          Lunch break
        </div>
        <div class="col-xs-12 col-sm-6">
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          12:30 - 13:00
        </div>
        <div class="col-xs-12 col-sm-2">
          Poster session #1
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Training Neural Networks to Produce Compatible Features</strong><br />
          <span style="color:#999999;font-weight: bold">Michael Gygli, Jasper Uijlings, Vittorio Ferrari</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Exploring Latent Class Structures in Classification-By-Components Networks</strong><br />
          <span style="color:#999999;font-weight: bold">Lars Holdijk</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Decomposing Image Generation into Layout Prediction and Conditional Synthesis</strong><br />
          <span style="color:#999999;font-weight: bold">Anna Volokitin, Ender Konukoglu, Luc Van Gool</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Semantic Bottleneck Layers: Quantifying and Improving Inspectability of Deep
            Representations</strong><br>
          <span style="color:#999999;font-weight: bold">Max Losch, Mario Fritz, Bernt Schiele</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          13:00 - 13:45
        </div>
        <div class="col-xs-12 col-sm-2">
          Keynote talk
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Unsupervised Representations towards Counterfactual Predictions</strong><br />
          <a href='https://www.cs.toronto.edu/~garg/' target="_blank"><strong>Animesh Garg</strong></a>,
          <span style='color:#999999;'>University of Toronto</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          13:45 - 14:30
        </div>
        <div class="col-xs-12 col-sm-2">
          Keynote talk
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Composing Humans and Objects in the 3D World</strong><br />
          <a href='https://people.eecs.berkeley.edu/~kanazawa/' target="_blank"><strong>Angjoo Kanazawa</strong></a>,
          <span style='color:#999999;'>University of California, Berkeley</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          14:30 - 15:15
        </div>
        <div class="col-xs-12 col-sm-2">
          Live panel discussion
        </div>
        <div class="col-xs-12 col-sm-6">
          Panelists:
          <ul>
            <li><strong>Jitendra Malik</strong></li>
            <li><strong>Aude Oliva</strong></li>
            <li><strong>Chelsea Finn</strong></li>
            <li><strong>Animesh Garg</strong></li>
            <li><strong>Angjoo Kanazawa</strong></li>
          </ul>
          Moderated by Ranjay Krishna
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          15:15 - 15:45
        </div>
        <div class="col-xs-12 col-sm-2">
          Afternoon break
        </div>
        <div class="col-xs-12 col-sm-6">
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          15:45 - 16:05
        </div>
        <div class="col-xs-12 col-sm-2">
          Oral talk #1
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Compositional Convolutional Neural Networks: A Deep Architecture with Innate Robustness to Partial
            Occlusion</strong><br />
          <span style='color:#999999;font-weight: bold'>Adam Kortylewski, Ju He, Qing Liu, Alan Yuille</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          16:05 - 16:25
        </div>
        <div class="col-xs-12 col-sm-2">
          Oral talk #2
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>PaStaNet: Toward Human Activity Knowledge Engine</strong><br />
          <span style='color:#999999;font-weight: bold'>Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi
            Wang, Hao-Shu Fang, Ze Ma, Mingyang Chen, Cewu Lu</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          16:25 - 16:45
        </div>
        <div class="col-xs-12 col-sm-2">
          Oral talk #3
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Searching for Actions on the Hyperbole</strong><br />
          <span style='color:#999999;font-weight: bold'>Teng Long, Pascal Mettes, Heng Tao Shen, Cees Snoek</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
          16:45 - 17:15
        </div>
        <div class="col-xs-12 col-sm-2">
          Poster session #2
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Inferring Temporal Compositions of Actions Using Probabilistic Automata</strong><br />
          <span style='color:#999999;font-weight: bold'>Rodrigo Santa Cruz, Anoop Cherian, Basura Fernando, Dylan
            Campbell, Stephen Gould</span>
        </div>
      </div>

      <div class="row slot-colored">
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-2">
        </div>
        <div class="col-xs-12 col-sm-6">
          <strong>Understanding Action Recognition in Still Images</strong><br />
          <span style='color:#999999;font-weight: bold'>Deeptha Girish, Vineeta Singh, Anca Ralescu</span>
        </div>
      </div>

      <div class="row slot">
        <div class="col-xs-12 col-sm-2">
          17:15 - 17:30
        </div>
        <div class="col-xs-12 col-sm-2">
          Closing remarks
        </div>
        <div class="col-xs-12 col-sm-6">
        </div>
      </div>

      -->

      <hr />

      <!-- Speakers -->
      <p><a class="anchor" id="speakers"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Keynote Speakers</h2>
        </div>
      </div>

      <!-- Speaker -->
      
      <div class="row">
        <div class="col-xs-12 col-sm-3">
          <b>TBD</b>.
        </div>
        <div class="col-xs-12 col-sm-9">
          <b>TBD</b>.
        </div>
      </div>
      <br />
      
      <!--
      <div class="row">
        <div class="col-xs-12 col-sm-3">
          <div class="instructor">
            <div class="instructorphoto"><img src="images/tbd.png"></div>
          </div>
        </div>
        <div class="col-xs-12 col-sm-9">
          <b><a href="TBD" target="_blank">TBD</a></b>.
        </div>
      </div>
      <br />
      -->

      <hr />

      <!-- Organizers
      <p><a class="anchor" id="organizers"></a></p>
      <div class="row">
        <div class="col-xs-12">
          <h2>Organizers</h2>
          <div>
            <div class="instructor">
              <a href="https://profiles.stanford.edu/jingwei-ji" target="_blank">
                <div class="instructorphoto"><img
                    src="https://cs.stanford.edu/people/jingweij/images/jingwei_100x100.png"></div>
                <div>Jingwei Ji</div>
              </a>
            </div>
            <div class="instructor">
              <a href="https://ranjaykrishna.com" target="_blank">
                <div class="instructorphoto"><img src="https://cs.stanford.edu/people/ranjaykrishna/images/ranjay.png">
                </div>
                <div>Ranjay Krishna</div>
              </a>
            </div>
            <div class="instructor">
              <a href="https://stanford.edu/~eadeli/" target="_blank">
                <div class="instructorphoto"><img src="https://stanford.edu/~eadeli/images/MyPhoto03.jpg"></div>
                <div>Ehsan Adeli</div>
              </a>
            </div>
            <br />
            <br />
            <div class="instructor">
              <a href="https://www.niebles.net/" target="_blank">
                <div class="instructorphoto"><img src="https://www.niebles.net/images/jcbwcircle.jpg"></div>
                <div>Juan Carlos Niebles</div>
              </a>
            </div>
            <div class="instructor">
              <a href="https://www.cs.princeton.edu/~olgarus/index.html" target="_blank">
                <div class="instructorphoto"><img src="https://visualai.princeton.edu/photos/OlgaRussakovsky.jpg"></div>
                <div>Olga Russakovsky</div>
              </a>
            </div>
            <div class="instructor">
              <a href="https://profiles.stanford.edu/fei-fei-li/" target="_blank">
                <div class="instructorphoto"><img src="https://cs.stanford.edu/people/karpathy/densecap/feifei2.jpeg">
                </div>
                <div>Fei-Fei Li</div>
              </a>
            </div>
          </div>
        </div>
      </div>
      <p class='important'>Please contact Jingwei Ji or Ranjay Krishna with any questions: jingweij / ranjaykrishna [at]
        cs [dot] stanford [dot] edu.</p>
      <hr />
      -->

      <!-- Important Dates -->
      <p><a class="anchor" id="dates"></a></p>
      <div class="row" style="margin-top:30px;">
        <div class="col-xs-12 col-sm-12">
          <h2>Important Dates and Details</h2>
          <ul>
            <!--<li><b>Signup to receive updates</b>: <s>using <a href='https://forms.gle/kZTP1eqpgs6gzm9x7'>this
                  form</a></s></li>-->
            <li><b>Paper submission deadline</b>: March 21st. CMT portal: <a
                  href="TBD">Coming soon!</a></s></li>
            <li><b>Notification of acceptance</b>: April 24th</li>
            <li><b>Camera ready due</b>: May 3rd</li>
            <li><b>Workshop date</b>: June 17th or 18th, TBD</li>
          </ul>
          </p>
        </div>
      </div>
      <hr />
    </div>
  </div>


  <!-- jQuery and Boostrap -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
</body>

</html>